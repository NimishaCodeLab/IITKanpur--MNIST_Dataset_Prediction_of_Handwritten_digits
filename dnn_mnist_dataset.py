# -*- coding: utf-8 -*-
"""DNN_MNIST_Dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19NFQDlt-iBz5slpR0aela8UaSKqoGica
"""

from sklearn.datasets import load_digits 
digits_dataset=load_digits()
print(type(digits_dataset))
print(digits_dataset.DESCR)

digits_dataset

print(digits_dataset.data.shape)
print(set(digits_dataset.data.flatten()))
print(digits_dataset.data.max())
print(digits_dataset.data.min())

X=digits_dataset.data

y=digits_dataset.target

X/=X.max()

X.max(),X.min()

import numpy as np
import matplotlib.pyplot as plt

import cv2
import seaborn as sns
from PIL import Image


random_indexs=np.random.randint(0,digits_dataset.data.shape[0],size=(9,))

for plot_number,index in enumerate(random_indexs):
  plt.subplot(3,3,plot_number+1)
  plt.imshow( X[index].reshape(8,8),cmap='gray')
  plt.axis('off')
  plt.title( y[index])
plt.tight_layout()
plt.show()

X[0].shape

# split data 
from sklearn.neural_network import MLPClassifier

from sklearn.model_selection import train_test_split 
Xtrain,Xtest,ytrain,ytest=train_test_split(X,y)

nn_clf=MLPClassifier(hidden_layer_sizes=(128,),activation='relu',solver='adam',learning_rate='constant',learning_rate_init=0.001,max_iter=1000,tol=0.001,verbose=True  ,batch_size='auto',early_stopping=True,validation_fraction=0.1)
nn_clf.fit(Xtrain,ytrain)

nn_clf.score(Xtest,ytest)

nn_clf.score(Xtrain,ytrain)

random_indexs=np.random.randint(0,Xtest.shape[0],size=(9,))
for plot_number,index in enumerate(random_indexs):
  plt.subplot(3,3,plot_number+1)
  plt.imshow( X[index].reshape(8,8),cmap='gray')
  prediction= nn_clf.score(Xtest[index])
  plt.axis('off')
  plt.title( y[index])
plt.tight_layout()
plt.show()

random_indexs=np.random.randint(0,digits_dataset.data.shape[0],size=(9,))

nn_clf.predict([Xtest[0],Xtest[2]])#multiple samples

nn_clf.predict([Xtest[0]])#single sample

Xtest[0].reshape(1,64).shape

np.expand_dims(Xtest[0],axis=0).shape

ytest[0],ytest[2]

random_indexs=np.random.randint(0,Xtest.shape[0],size=(9,))
for plot_number,index in enumerate(random_indexs):
  plt.subplot(3,3,plot_number+1)
  plt.imshow( Xtest[index].reshape(8,8),cmap='gray')
  prediction= nn_clf.predict([Xtest[index]])[0]
  plt.axis('off')
  plt.title( f'pred: {prediction}, True: {ytest[index]}')
plt.tight_layout()
plt.show()

import tensorflow as tf

(Xtrain,ytrain),(Xtest,ytest)=tf.keras.datasets.mnist.load_data()

Xtrain.shape

Xtrain.reshape(Xtrain.shape[0],-1).shape

Xtrain.max(),Xtrain.min(),np.max(Xtest),np.min(Xtest)

import numpy as np
Xtrain=Xtrain.reshape(-1,np.prod(Xtrain.shape[1:]))
Xtest=Xtest.reshape(-1,np.prod(Xtest.shape[1:]))
Xtrain.shape,Xtest.shape

# import numpy as np

# Xtrain = np.array(Xtrain)
# Xtest = np.array(Xtest)

# Xtrain = (Xtrain / Xtrain.max()).astype('float32')
# Xtest = (Xtest / Xtest.max()).astype('float32')

Xtrain.max(),Xtrain.min(),np.max(Xtest),np.min(Xtest),Xtrain.dtype,Xtest.dtype

import numpy as np

Xtrain = (Xtrain / np.max(Xtrain)).astype('float32')
Xtest = (Xtest / np.max(Xtest)).astype('float32')
Xtrain.max(),Xtrain.min(),np.max(Xtest),np.min(Xtest),Xtrain.dtype,Xtest.dtype

from sklearn.neural_network import MLPClassifier

nn_clf=MLPClassifier(hidden_layer_sizes=(64,128,),activation='relu',solver='adam',learning_rate='constant',learning_rate_init=0.001,max_iter=1000,tol=0.001,verbose=True  ,batch_size='auto',early_stopping=True,validation_fraction=0.1)
nn_clf.fit(Xtrain,ytrain)

print('Training accuracy:',nn_clf.score(Xtrain,ytrain))
print('Testing accuracy:',nn_clf.score(Xtest,ytest))





[w.shape for w in nn_clf.coefs_]#weights (w or m) in eq y= mx+b
#inputs (columns) -> 64 equations -> outputs(10)
#(784, 64) -> 64 equations each having 784 inputts (w)
#(64, 128) -> 128 equations each having 64 inputs (w)
#(128, 10) ->10 (total outputs classes)

[w.shape for w in nn_clf.intercepts_]#weights

!nvidia-smi

!nvidia-smi -L

import tensorflow as trf

trf.device('cpu')

trf.config.list_physical_devices()

trf.config.list_physical_devices('CPU')

trf.config.list_physical_devices('GPU')

trf.test.is_gpu_available()

trf.test.is_built_with_cuda()

trf.config.experimental.get_device_details('trf.config.list_physical_devices('GPU')[0]')

(Xtrain,ytrain),(Xtest,ytest)=trf.keras.datasets.mnist.load_data()

Xtrain=(Xtrain/Xtrain.max()).astype('float32')
Xtest=(Xtest/Xtest.max()).astype('float32')
Xtrain.max(),Xtrain.min(),Xtest.max(),Xtest.min(),Xtrain.dtype,Xtest.dtype

Xtrain.shape,ytrain.shape,Xtest.shape,ytest.shape

model=trf.keras.Sequential(layers=None,name='mnist_clf')
model.add(trf.keras.layers.Flatten(input_shape=(28, 28),name='flatten_00'))
model.add(trf.keras.layers.Dense(64,activation='relu',use_bias=True,name='dense_64_01'))
model.add(trf.keras.layers.Dense(128,activation='relu',use_bias=True,name='dense_128_02'))
model.add(trf.keras.layers.Dense(10,activation='softmax',use_bias=True,name='dense_10_03_output'))

inputs=trf.random.normal((1,28,28))
output=model(inputs)
output.shape
output

model.summary()



f=trf.keras.layers.Flatten(name='flatten_00')
inputs=trf.random.normal((3,4,5,7))
f(inputs).shape

model.name



inputs=trf.random.uniform((3,128,))

d=trf.keras.layers.Dense(64,activation='relu',use_bias=True,kernel_initializer='zero')
outputs=d(inputs)
outputs.shape

d.weights

d.weights[0].shape,d.weights[1].shape

d.weights[0]

d.weights[1]

model.compile(optimizer='adam',loss='SparseCategoricalCrossentropy',metrics=None)

model.compile(optimizer=trf.keras.optimizers.Adam(learning_rate=0.001),loss=trf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=None)

history=model.fit(Xtrain,ytrain,batch_size=32,epochs=5,verbose='auto',validation_data=(Xtest,ytest),validation_split=None,shuffle=True)

history

history=model.fit(Xtrain,ytrain,batch_size=32,epochs=3,verbose=1,validation_data=(Xtest,ytest),validation_split=None,shuffle=True)

history.history

model.compile(optimizer=trf.keras.optimizers.Adam(learning_rate=0.001),loss=trf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=[trf.keras.metrics.SparseCategoricalAccuracy()])

history=model.fit(Xtrain,ytrain,batch_size=32,epochs=3,verbose=1,validation_data=(Xtest,ytest),validation_split=None,shuffle=True)

history.history

import pandas as pd
import matplotlib.pyplot as plt

pd.DataFrame(data=history.history).head()

pd.DataFrame(data=history.history).tail()

pd.DataFrame(data=history.history)[['sparse_categorical_accuracy','val_sparse_categorical_accuracy']].plot()
plt.xlabel('epochs'),plt.ylabel('accuracy'),plt.grid(),plt.title('Accuracy')
plt.savefig('accuracy.png',dpi=480)
plt.show()

plt.xlabel('epochs'),plt.ylabel('accuracy'),plt.grid(),plt.title('Accuracy')
plt.savefig('accuracy.png',dpi=480)
plt.show()

pd.DataFrame(data=history.history)[['loss','val_loss']].plot()
plt.xlabel('epochs'),plt.ylabel('loss'),plt.grid(),plt.title('loss')
plt.savefig('loss.png',dpi=480)
plt.show()

model.compile(optimizer=trf.keras.optimizers.Adam(learning_rate=0.001),loss=trf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=None)
early_stopping=trf.keras.callback.EarlyStopping(monitor='val_loss',min_delta=0,mode='auto',restore_best_weights=True,start_from_epochs=0,patience=3)

history=model.fit(Xtrain,ytrain,batch_size=32,epochs=3,verbose=1,validation_data=(Xtest,ytest),validation_split=None,shuffle=True,callback=[early_stopping])

results:dict=model.evaluate(Xtest,ytest,batch_size=None,verbose='auto',return_dict=True)
print(results)

model(Xtest)

model.predict(Xtest)

outputs=model.predict(trf.expand_dims(Xtest[0],axis=0))

trf.math.round(trf.nn.softmax(outputs),0)

import numpy as np
np.round(trf.nn.softmax(outputs),3)

np.argmax(trf.nn.softmax(outputs),axis=1)





Xtest[0].shape

trf.expand_dims(Xtest[0],axis=0)

trf.expand_dims(Xtest[0],axis=0).shape

import tensorflow as tf

(Xtrain,ytrain),(Xtest,ytest)=tf.keras.datasets.fashion_mnist.load_data()

Xtrain.dtype

ytrain.dtype

print(type(Xtrain))
print(type(ytrain))
print(type(Xtest))
print(type(ytest))

print("Xtrain shape:", Xtrain.shape)
print("ytrain shape:", ytrain.shape)
print("Xtest shape:", Xtest.shape)
print("ytest shape:", ytest.shape)

import numpy as np

unique_labels = np.unique(ytrain)
print("Unique labels in ytrain:", unique_labels)

class_names = {
    0: 'T-shirt/top',
    1: 'Trouser',
    2: 'Pullover',
    3: 'Dress',
    4: 'Coat',
    5: 'Sandal',
    6: 'Shirt',
    7: 'Sneaker',
    8: 'Bag',
    9: 'Ankle boot'
}


for label, name in class_names.items():
    print(f"Label {label}: {name}")

min_pixel_value = Xtrain.min()
max_pixel_value = Xtrain.max()

print("Pixel range:")
print("Minimum pixel value:", min_pixel_value)
print("Maximum pixel value:", max_pixel_value)

Xtrain_rescaled = Xtrain / 255.0
Xtest_rescaled = Xtest / 255.0

import numpy as np

Xtrain = (Xtrain / np.max(Xtrain)).astype('float32')
Xtest = (Xtest / np.max(Xtest)).astype('float32')
Xtrain.max(),Xtrain.min(),np.max(Xtest),np.min(Xtest),Xtrain.dtype,Xtest.dtype

import matplotlib.pyplot as plt
plt.figure(figsize=(10, 10))
for i in range(25):
    plt.subplot(5, 5, i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(Xtrain[i], cmap=plt.cm.binary)
plt.suptitle("Rescaled Xtrain Data")
plt.show()


plt.figure(figsize=(10, 10))
for i in range(25):
    plt.subplot(5, 5, i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(Xtest[i], cmap=plt.cm.binary)
plt.suptitle("Rescaled Xtest Data")
plt.show()

import tensorflow as trf

model=trf.keras.Sequential(layers=None,name='fashion_mnist_clf')
model.add(trf.keras.layers.Flatten(input_shape=(28, 28),name='flatten_00'))
model.add(trf.keras.layers.Dense(64,activation='relu',use_bias=True,name='dense_64_01'))
model.add(trf.keras.layers.Dense(128,activation='relu',use_bias=True,name='dense_128_02'))
model.add(trf.keras.layers.Dense(10,activation='softmax',use_bias=True,name='dense_10_03_output'))

model.summary()

f=trf.keras.layers.Flatten(name='flatten_00')
inputs=trf.random.normal((3,4,5,7))
f(inputs).shape

d=trf.keras.layers.Dense(64,activation='relu',use_bias=True,kernel_initializer='zero')
outputs=d(inputs)
outputs.shape

d.weights

model.compile(optimizer='adam',loss='SparseCategoricalCrossentropy',metrics=None)

model.compile(optimizer=trf.keras.optimizers.Adam(learning_rate=0.001),loss=trf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=None)

